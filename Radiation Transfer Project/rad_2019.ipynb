{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13d0f5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: miepython in /srv/conda/envs/notebook/lib/python3.11/site-packages (2.5.4)\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/notebook/lib/python3.11/site-packages (from miepython) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /srv/conda/envs/notebook/lib/python3.11/site-packages (from miepython) (3.8.4)\n",
      "Requirement already satisfied: numba in /srv/conda/envs/notebook/lib/python3.11/site-packages (from miepython) (0.58.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from matplotlib->miepython) (2.9.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from numba->miepython) (0.41.1)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->miepython) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import re\n",
    "import linecache \n",
    "# Uncomment below line if miepython hasn't been install\n",
    "%pip install miepython\n",
    "import miepython\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d2a11",
   "metadata": {},
   "source": [
    "# Loading in Data\n",
    "This data comes from the NASA Langley Research Center's Airborne Science Data for Atmopheric Composition [repository](https://www-air.larc.nasa.gov/). Aerosol data was recorded on NASA SARP flights from the [Langley Aerosol Research Group](https://science-data.larc.nasa.gov/large/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b230d",
   "metadata": {},
   "source": [
    "### Creating One Dataframe\n",
    "Relevant variables were merged using LaRC's Custom Data Merging Tool. Files are in .ict format but can still be read with pd.read_csv. The first lines in the .ict files are all the metadata and must be skipped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d7b099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"raw_data/2019/merged_2019_SARP/\"\n",
    "all_files = glob.glob(path + \"*.ict\")\n",
    "all_files.sort()\n",
    "all_files\n",
    "\n",
    "li = []\n",
    "flight_number=['1','2','3']\n",
    "index = 0\n",
    "for filename in all_files:\n",
    "    # column headers start on line 162 so we skip 161 rows\n",
    "    df = pd.read_csv(filename, index_col=None, header=0, skiprows=161)\n",
    "    df[\"flight number\"] = [flight_number[index] for i in range(len(df))]\n",
    "    li.append(df)\n",
    "    index = index+1\n",
    "\n",
    "all_raw = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2036f7",
   "metadata": {},
   "source": [
    "### FIREX-AQ Dataframe\n",
    "In 2019 [FIREX-AQ](https://csl.noaa.gov/projects/firex-aq/) instruments were used on the 2019 SARP flights. Black carbon data is only available via the FIREX-AQ datasets. We load in the FIREX-AQ datasets from the SARP flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a19918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"raw_data/2019/merged_2019_FIREXAQ/\"\n",
    "all_files = glob.glob(path + \"*.ict\")\n",
    "all_files.sort()\n",
    "all_files\n",
    "\n",
    "li = []\n",
    "flight_number=['1','2','3']\n",
    "index = 0\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0, skiprows=187)\n",
    "    df[\"flight number\"] = [flight_number[index] for i in range(len(df))]\n",
    "    li.append(df)\n",
    "    index = index+1\n",
    "\n",
    "all_raw_fire = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2ea32",
   "metadata": {},
   "source": [
    "### Dataframe Cleaning\n",
    "Reduce SARP and FIREX-AQ dataframes to only include observations from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f70fe1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_fire = all_raw_fire[all_raw_fire['Time_Start'].isin(all_raw['Time_Start'].unique())]\n",
    "all_raw = all_raw[all_raw['Time_Start'].isin(all_raw_fire['Time_Start'].unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf58fc1",
   "metadata": {},
   "source": [
    "### Adding Datetime Variables\n",
    "LaRC data uses Day_Of_Year which must be converted to date. LaRC also has Time_Start and Time_Stop in UTC seconds which must be converted to h:m:s. The h:m:s start time and the date are combinded to create one datetime variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c703b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sarp\n",
    "\n",
    "# add year\n",
    "all_raw['year'] = 2019\n",
    "\n",
    "# convert year and Day_Of_year to date\n",
    "all_raw['date'] = pd.to_datetime(all_raw['year'] * 1000 + all_raw[' Day_Of_Year'], format='%Y%j')\n",
    "\n",
    "# convert start and stop times to h:m:s format\n",
    "all_raw['Time_Start hms'] = pd.to_datetime(all_raw['Time_Start'], unit='s').apply(lambda x: x.strftime(\"%H:%M:%S\"))\n",
    "all_raw['Time_Stop hms'] = pd.to_datetime(all_raw[' Time_Stop'], unit='s').apply(lambda x: x.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# combine h:m:s format and date to create datetime\n",
    "all_raw['datetime_start'] = pd.to_datetime(all_raw['date'].astype(str) + ' ' + all_raw['Time_Start hms'].astype(str))\n",
    "\n",
    "\n",
    "# for firexaq\n",
    "\n",
    "# add year\n",
    "all_raw_fire['year'] = 2019\n",
    "\n",
    "# convert year and Day_Of_year to date\n",
    "all_raw_fire['date'] = pd.to_datetime(all_raw_fire['year'] * 1000 + all_raw_fire[' Day_Of_Year'], format='%Y%j')\n",
    "\n",
    "# convert start and stop times to h:m:s format\n",
    "all_raw_fire['Time_Start hms'] = pd.to_datetime(all_raw_fire['Time_Start'], unit='s').apply(lambda x: x.strftime(\"%H:%M:%S\"))\n",
    "all_raw_fire['Time_Stop hms'] = pd.to_datetime(all_raw_fire[' Time_Stop'], unit='s').apply(lambda x: x.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# combine h:m:s format and date to create datetime\n",
    "all_raw_fire['datetime_start'] = pd.to_datetime(all_raw_fire['date'].astype(str) + ' ' + all_raw_fire['Time_Start hms'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18bf49",
   "metadata": {},
   "source": [
    "### Merge Datasets\n",
    "Merge FIREX-AQ data and SARP data so the black carbon variable is now in the SARP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9bf3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw = pd.merge(all_raw,all_raw_fire[['datetime_start',' BC_mass_90_550_nm_SCHWARZ']],on='datetime_start', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac367ac3",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "We only want to look at observations underneath the boundary layer which we set at 2000 feet. We want to remove all negative values and replace with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6c717ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries under 2000 ft\n",
    "df_new_under2k = all_raw[all_raw[' Pressure_Altitude'] <= 2000]\n",
    "\n",
    "# replace -999999 and -888888 values with NaN\n",
    "df_new_under2k = df_new_under2k.replace({-999999: np.nan})\n",
    "df_new_under2k = df_new_under2k.replace({-888888: np.nan})\n",
    "\n",
    "# checking for negative values\n",
    "check = pd.DataFrame(df_new_under2k.min())\n",
    "\n",
    "# removing negative values\n",
    "df_new_under2k[df_new_under2k[[\" NR_Chloride_PM1_AMS_JIMENEZ\",\n",
    "         \" Seasalt_PM1_AMS_JIMENEZ\",\n",
    "         \" MSA_PM1_AMS_JIMENEZ\",\n",
    "         \" ClO4_PM1_AMS_JIMENEZ\",\n",
    "         \" Bromine_PM1_AMS_JIMENEZ\",\n",
    "         \" Iodine_PM1_AMS_JIMENEZ\",\n",
    "         \" OSc_PM1_AMS_JIMENEZ\",\n",
    "         \" f57_PM1_AMS_JIMENEZ\",\n",
    "         \" f60_PM1_AMS_JIMENEZ\",\n",
    "         \" f82_PM1_AMS_JIMENEZ\",\n",
    "         \" f91_PM1_AMS_JIMENEZ\",\n",
    "         \" fC4H9_PM1_AMS_JIMENEZ\",\n",
    "         \" fC2H4O2_PM1_AMS_JIMENEZ\",\n",
    "         \" fC7H7_PM1_AMS_JIMENEZ\",\n",
    "         \" Abs532_stdPT_MOORE\"]] < 0] = np.NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73454166",
   "metadata": {},
   "source": [
    "# Scientific Processing\n",
    "We are using the Langley Aerosol Research Group data to estimate the refractive index and the size of the aerosols."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69a94c",
   "metadata": {},
   "source": [
    "## Composition and Refractive Index\n",
    "Organics, Ammonium Nitrate, Ammonium Sulfate, and Black Carbon all have different refractive indices. If we want to determine a total refractive index for the time interval, we must determine what fraction of the sample belongs to each aerosol. We will then use those weights and the aerosols' know refractive indices to create a weighted refractive index. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61776d",
   "metadata": {},
   "source": [
    "### Aligning Units\n",
    "Organics, Sulfate, Nitrate, and Ammonium are measured in µg/m<sup>3</sup>. Black Carbon is measured in ng/m<sup>3</sup>. We convert black carbon to µg/m<sup>3</sup> so the units align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b095ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BC_mass_90_550_nm_SCHWARZ in ng std m-3\n",
    "#PM1_AMS_JIMENEZ in ug sm-3\n",
    "#both are in standard cubic meters, BC is in nanograms and others are in micrograms\n",
    "\n",
    "df_new_under2k[' BC_mass_90_550_nm_SCHWARZ'] = df_new_under2k[' BC_mass_90_550_nm_SCHWARZ']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7713bcd",
   "metadata": {},
   "source": [
    "### Ammonium Nitrate and Ammonium Sulfate\n",
    "Ammonium, Nitrate, and Sulfate ion concentrations are recorded instead of the concentrations of Ammonium Nitrate and Ammonium Sulfate. The following formulas are used to determine the concentrations based on the ions. We are using the molecular weight of sulfate ($mm_{SO_4}$) and the molecular weight of nitrate ($mm_{NO_3}$).\n",
    "\n",
    "$ (NH_4)_2SO_4 = [SO_4 ^{2-}] + \\frac{[SO_4^{2-}]\\div mm_{SO_4} \\times 2}{([SO_4 ^{2-}]\\div mm_{SO_4} \\times 2)+([NO_3 ^{-}]\\div mm_{NO_3})} \\times [NH_4^{+}] $ \n",
    "\n",
    "$ NH_4NO_3 = [NO_3 ^{-}] + \\frac{[NO_3 ^{-}]\\div mm_{NO_3}}{([SO_4 ^{2-}]\\div mm_{SO_4} \\times 2)+([NO_3 ^{-}]\\div mm_{NO_3})} \\times [NH_4^{+}] $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3be7a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecular weight of sulfate is 96.07 g/mol\n",
    "sul_mm = 96.07\n",
    "# molecular wight of nitrate is 62.005 g/mol\n",
    "nit_mm = 62.005\n",
    "\n",
    "# calculate ammonium sulfate concentration\n",
    "df_new_under2k['NH42SO4'] = df_new_under2k[' Sulfate_PM1_AMS_JIMENEZ'] + (((df_new_under2k[' Sulfate_PM1_AMS_JIMENEZ']/sul_mm)*2)/(((df_new_under2k[' Sulfate_PM1_AMS_JIMENEZ']/sul_mm)*2)+(df_new_under2k[' Nitrate_PM1_AMS_JIMENEZ']/nit_mm)))*df_new_under2k[' Ammonium_PM1_AMS_JIMENEZ']\n",
    "\n",
    "# calculate ammonium nitrate concentration\n",
    "df_new_under2k['NH4NO3'] = df_new_under2k[' Nitrate_PM1_AMS_JIMENEZ'] + ((df_new_under2k[' Nitrate_PM1_AMS_JIMENEZ']/nit_mm)/(((df_new_under2k[' Sulfate_PM1_AMS_JIMENEZ']/sul_mm)*2)+(df_new_under2k[' Nitrate_PM1_AMS_JIMENEZ']/nit_mm)))*df_new_under2k[' Ammonium_PM1_AMS_JIMENEZ']\n",
    "\n",
    "# uncomment line below to test to make sure code works\n",
    "# print(df_new_under2k[' Sulfate_PM1_AMS_JIMENEZ'] + df_new_under2k[' Nitrate_PM1_AMS_JIMENEZ'] + df_new_under2k[' Ammonium_PM1_AMS_JIMENEZ'])\n",
    "# print( df_new_under2k['NH42SO4'] + df_new_under2k['NH4NO3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67d34a",
   "metadata": {},
   "source": [
    "### Composition Fraction\n",
    "The refractive index of the aerosol sample depends on what it is made of. We need to know what fraction of the sample is organics, ammonium nitrate, ammonium sulfate, and black carbon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d38e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summing up individual compositions to find the total composition\n",
    "df_new_under2k[\"comp_sum\"] = df_new_under2k[\" OA_PM1_AMS_JIMENEZ\"] + df_new_under2k[\"NH42SO4\"] + df_new_under2k[\"NH4NO3\"] + df_new_under2k[\" BC_mass_90_550_nm_SCHWARZ\"]\n",
    "\n",
    "# determining the fraction of each aerosol\n",
    "df_new_under2k[\"Org_frac\"] = df_new_under2k[\" OA_PM1_AMS_JIMENEZ\"]/df_new_under2k[\"comp_sum\"]\n",
    "df_new_under2k[\"NH42SO4_frac\"] = df_new_under2k[\"NH42SO4\"]/df_new_under2k[\"comp_sum\"]\n",
    "df_new_under2k[\"NH4NO3_frac\"] = df_new_under2k[\"NH4NO3\"]/df_new_under2k[\"comp_sum\"]\n",
    "df_new_under2k[\"BC_frac\"] = df_new_under2k[\" BC_mass_90_550_nm_SCHWARZ\"]/df_new_under2k[\"comp_sum\"]\n",
    "\n",
    "# check to make sure fraction code worked\n",
    "# print(df_new_under2k[\"Org_frac\"] + df_new_under2k[\"NH42SO4_frac\"] + df_new_under2k[\"NH4NO3_frac\"] + df_new_under2k[\"BC_frac\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b45be",
   "metadata": {},
   "source": [
    "### Weighted Refractive Index\n",
    "We will use the known refractive indices of Organics, Ammonium Nitrate, Ammonium Sulfate, and Black Carbon as well as our composition fractions to calculate a weighted refractive index. These refractive indices were used by [Langridge 2012](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2011JD017116). The refractive indices are complex numbers and therefore contain a real and imaginary part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecfe2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real and imaginary part for organics\n",
    "Org_rel = 1.63\n",
    "Org_im = 0.02\n",
    "\n",
    "# real and imaginary part for ammonium sulfate\n",
    "NH42SO4_rel = 1.53\n",
    "NH42SO4_im = 0\n",
    "\n",
    "# real and imaginary part for ammonium nitrate\n",
    "NH4NO3_rel = 1.6\n",
    "NH4NO3_im = 0\n",
    "\n",
    "# real and imaginary part for black carbon\n",
    "BC_rel = 1.95\n",
    "BC_im = 0.79\n",
    "\n",
    "# weighted real and imaginary part\n",
    "df_new_under2k['rel_av'] = df_new_under2k['Org_frac']*Org_rel + df_new_under2k['NH42SO4_frac']*NH42SO4_rel + df_new_under2k['NH4NO3_frac']*NH4NO3_rel + df_new_under2k['BC_frac']*BC_rel\n",
    "df_new_under2k['im_av'] = df_new_under2k['Org_frac']*Org_im + df_new_under2k['NH42SO4_frac']*NH42SO4_im + df_new_under2k['NH4NO3_frac']*NH4NO3_im + df_new_under2k['BC_frac']*BC_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af8fab",
   "metadata": {},
   "source": [
    "## Aerosol Size\n",
    "Aerosol size data is given by the concentration of aerosols within a certain diameter distribution bin. There are multiple bins within a dataset. Average diameter is determinded by summing up the aerosols across all bins and finding the weight of each bin. The weight is then multiplied by the diameter the bin represents to find a weighted diameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98338b3",
   "metadata": {},
   "source": [
    "### Diameter Bins\n",
    "Bin mid-point diameters were not in the merged metadata and has to be pulled from the raw LAS metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e889633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of bin columns\n",
    "collist = df_new_under2k.filter(like='LAScold_bin').columns.tolist()\n",
    "\n",
    "# pulls midpoint diameters from LAS metadata\n",
    "# bin mid-point diameters are in um\n",
    "sizes = linecache.getline(\"raw_data/2019/LAS_meta_SARP/SARP-LARGE-LAScold_DC8_20190716_R0.ict\", 115) \n",
    "\n",
    "# split sizes list based on multiple delimeters\n",
    "sizes = sizes.replace('OTHER_COMMENTS: Midpoint diameters of Bins 00 to 79 determined by DMA-classified ammonium sulfate calibrations are:', '')\n",
    "\n",
    "# Split sizes list based on multiple delimeters\n",
    "sizes = re.split(',|\\n|\\t', sizes)\n",
    "\n",
    "# Remove the empty elements from the list\n",
    "sizes = list(filter(None, sizes))\n",
    "\n",
    "# Convert element in the list from type string to type float\n",
    "sizes = [float(i) for i in sizes]\n",
    "\n",
    "# creates dataframe of bin mid-points and column names\n",
    "LAS = pd.DataFrame(\n",
    "    {'columns': collist,\n",
    "     'size': sizes\n",
    "    })\n",
    "\n",
    "# Midpoint diameters are in um, need in nm\n",
    "LAS['size'] = LAS['size']*1000\n",
    "\n",
    "# bin sizes range from year to year\n",
    "# LAS from 2016 has 100nm to 5011.9nm\n",
    "# LAS from 2019 has 100nm to 4796nm\n",
    "# UHSAS from 2024 has 60.9nm to 985.9nm\n",
    "\n",
    "# want range 100nm to 985.9nm\n",
    "LAS = LAS[(LAS['size'] >= 100) & (LAS['size'] <= 985.9) ]\n",
    "\n",
    "# turn sizes into an array\n",
    "size_array = np.array(LAS['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c77560",
   "metadata": {},
   "source": [
    "### Weighted Diameter\n",
    "Find sum of all aerosols for each observation and find the weight of each bin. Use weight and bin mid-point diameter to find weighted diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd5e0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum aerosols across all bins\n",
    "df_new_under2k['LAS_sum'] = df_new_under2k[LAS['columns']].sum(axis=1)\n",
    "\n",
    "# create a new dataframe where each bin value is divided by the sum of all bins\n",
    "weighted_df = df_new_under2k[LAS['columns']].div(df_new_under2k['LAS_sum'], axis=0)\n",
    "\n",
    "# multiply each weight by the corresponding bin diameter\n",
    "for i in range(len(LAS['columns'])):\n",
    "   weighted_df[weighted_df.columns[i]] = weighted_df[weighted_df.columns[i]]*size_array[i]\n",
    "\n",
    "# sum diameters\n",
    "df_new_under2k['LAS_weighted'] = weighted_df[LAS['columns']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378a329",
   "metadata": {},
   "source": [
    "# Calculating Radiative Forcing\n",
    "The weighted refractive index and weighted diameter can now be used to find the radiative forcing efficiency of the aerosols."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ffa7e",
   "metadata": {},
   "source": [
    "## Final Cleaning\n",
    "SSA is calculated from Abs532_stdPT_MOORE and drySC550_stdPT_MOORE. Observations without complete compostion, size, or optical data are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20e142eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data without refractive index, size or SSA variables\n",
    "df_new_under2k = df_new_under2k.dropna(subset=[\" Abs532_stdPT_MOORE\",\"rel_av\"])\n",
    "\n",
    "# calculate SSA from scattering and absorption\n",
    "df_new_under2k[\"SSA\"] = df_new_under2k[\" drySC550_stdPT_MOORE\"]/(df_new_under2k[\" drySC550_stdPT_MOORE\"] + df_new_under2k[\" Abs532_stdPT_MOORE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2abf63c",
   "metadata": {},
   "source": [
    "## Calculations\n",
    "The following code chunck performs 5 crutial steps:\n",
    "\n",
    "1. Use the weighted diameter to calculate size parameter.\n",
    "The mie code needs the size parameter. The size parameter ($x$) is calculated with diameter ($d$) and $\\lambda$, which for us is 550 nm. The diameter and $\\lambda$ must be in the same units.\n",
    "\n",
    "$$\n",
    "x = \\frac{d\\pi}{\\lambda} \n",
    "$$\n",
    "\n",
    "2. We use [miepython](https://miepython.readthedocs.io/en/latest/index.html) which takes refractive index and size parameter as variables. The code outputs 3 dimensionless efficiencies, but we are the most interested in the back-scattering efficiency ($Q_{back}$) and the scattering efficiency ($Q_{sca}$).\n",
    "\n",
    "3. We use the $Q_{back}$ and the $Q_{sca}$ values to find the hemispheric backscatter fraction ($b$). \n",
    "\n",
    "$$\n",
    "b = \\frac{Q_{back}}{Q_{sca}\\times 4 \\pi}\n",
    "$$\n",
    "\n",
    "4. We find the average upscatter fraction ($\\beta$) using the hemispheric backscatter fraction. We utalize the following equation by [Anderson 1999](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/1999JD900172).\n",
    "\n",
    "$$\n",
    "\\beta = 0.082 + 1.85b -2.97b^2\n",
    "$$\n",
    "\n",
    "5. Relative radiative forcing is found with the following equation from [Langridge 2012](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2011JD017116). Our constants are the solar constant ($S_0$), atmospheric transmission ($T$), cloud fraction ($A_C$), and surface albedo ($R$). We are using the same constant values as in the paper.\n",
    "\n",
    "$$\n",
    "\\Delta F_{eff} = -0.5 S_0 T^2 (1-A_C) SSA \\beta \\times \\{(1-R)^2 - (\\frac{2R}{\\beta})[(\\frac{1}{SSA})-1]\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8935b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes chained argument warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# create upscatter fraction function\n",
    "# function from Alyson Fritzmann\n",
    "def back_scat(i):\n",
    "    beta = .082 + 1.85*i -2.97*(i**2)\n",
    "    return beta\n",
    "\n",
    "# set constants for equation, based on those from Langridge 2012\n",
    "S_o = 1366\n",
    "T = .76\n",
    "A_c = 0\n",
    "R = 0.14\n",
    "\n",
    "# create radiative forcing function\n",
    "# function from Alyson Fritzmann\n",
    "def rad_forcing(SSA,BETA):\n",
    "    Feff = -0.5*S_o*(T**2)*SSA*BETA*(1-A_c)*((1-R)**2 - (((2*R)/BETA)*((1/SSA) - 1)))\n",
    "    return Feff\n",
    "\n",
    "# create blank variables that will get filled during loop\n",
    "df_new_under2k['ref'] = \"\"\n",
    "df_new_under2k['rad'] = \"\"\n",
    "df_new_under2k['sizeparam'] = \"\"\n",
    "df_new_under2k['backscatter_frac'] = \"\"\n",
    "df_new_under2k['upscatter_frac'] = \"\"\n",
    "\n",
    "# loop for radiative forcing\n",
    "for index, row in df_new_under2k.iterrows():\n",
    "    # create variables for refractive index components, diameter, and lambda\n",
    "    rel = row['rel_av']\n",
    "    im = row['im_av']\n",
    "    diam = row['LAS_weighted']\n",
    "    lam = 550\n",
    "    # mie python does not assume imaginary part is negative, need to add it\n",
    "    m = complex(rel,-im)\n",
    "    df_new_under2k['ref'][index] = m\n",
    "    # STEP 1: create size parameter\n",
    "    # sphere size parameter is dimensionless, radius and lambda should be in nm\n",
    "    x = (diam*np.pi)/lam\n",
    "    df_new_under2k['sizeparam'][index] = x\n",
    "    # STEP 2: use mie code to find qback and qsca\n",
    "    qext, qsca, qback, g = miepython.mie(m,x)\n",
    "    # STEP 3: find backscatter fraction\n",
    "    b = (qback/qsca)/(4*np.pi)\n",
    "    df_new_under2k['backscatter_frac'][index] = b\n",
    "    # STEP 4: find upscatter fraction\n",
    "    beta = back_scat(b)\n",
    "    df_new_under2k['upscatter_frac'][index] = beta\n",
    "    # create variable for SSA\n",
    "    SSA = row['SSA']\n",
    "    # STEP 5: find relative radiative forcing\n",
    "    df_new_under2k['rad'][index] = rad_forcing(SSA,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35264f79",
   "metadata": {},
   "source": [
    "## Export Data\n",
    "We create new dataframe with only the columns we want for statistical analysis. This is saved as a .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10c3fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "clean_2019 = df_new_under2k[['datetime_start','year', ' Longitude',' Latitude','Org_frac','NH42SO4_frac','NH4NO3_frac','BC_frac','ref','sizeparam','backscatter_frac','upscatter_frac','SSA','rad']]\n",
    "# save as .csv\n",
    "clean_2019.to_csv('cleaned_data/clean_2019.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
